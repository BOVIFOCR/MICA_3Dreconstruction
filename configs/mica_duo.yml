# Mica config

pretrained_model_path: '/home/bjgbiesseck/GitHub/BOVIFOCR_MICA_3Dreconstruction/data/pretrained/mica.tar'

dataset:
  # root: '/home/bjgbiesseck/datasets/'
  root: '/datasets1/bjgbiesseck/MICA'

  # training_data: [ 'LYHM', 'D3DFACS', 'BU3DFE', 'FRGC', 'Stirling', 'FaceWarehouse', 'BP4D' ]    # original
  # training_data: [ 'FRGC', 'Stirling' ]                          # BERNARDO
  # training_data: [ 'FRGC', 'Stirling', 'LYHM', 'FLORENCE' ]      # BERNARDO
  training_data: [ 'FRGC', 'LYHM', 'FLORENCE', 'FACEWAREHOUSE' ]   # BERNARDO

  # eval_data: [ 'FLORENCE' ]      # original
  # eval_data: [ 'FACEWAREHOUSE' ]   # Bernardo
  eval_data: [ 'Stirling' ]      # Bernardo

  num_workers: 4    # original
  # num_workers: 1      # BERNARDO

  batch_size: 8

  # K: 2    # original
  K: 1      # BERNARDO

# Bernardo
# output_dir_annotation: '_TESTS_train=FRGC,LYHM,FLORENCE,FACEWAREHOUSE_eval=Stirling_pretrainedMICA=True_pretrainedARCFACE=ms1mv3-r100'
# output_dir_annotation: '_TESTS_train=FRGC,LYHM,FLORENCE,FACEWAREHOUSE_eval=Stirling_pretrainedMICA=True_pretrainedCOSFACE=glint360k-r100'
output_dir_annotation: '_TESTS_train=FRGC,LYHM,FLORENCE,FACEWAREHOUSE_eval=Stirling_pretrainedMICA=False_pretrainedCOSFACE=glint360k-r100'



train:
  lr: 1e-5
  arcface_lr: 1e-5
  weight_decay: 2e-4
  use_mask: True
  reset_optimizer: False
  max_steps: 160000
  log_steps: 50
  val_steps: 300
  vis_steps: 1200
  val_save_img: 1200
  checkpoint_steps: 1000
  checkpoint_epochs_steps: 10000

model:
  use_pretrained: False   # original
  # use_pretrained: True      # Bernardo
  n_shape: 300
  name: 'mica'
